{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<h1 align=\"center\">AIO Homework Module 03 Week 02</h1>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TYZq0pb-yLaB"
      },
      "source": [
        "# 1. KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbaKu-MIyI6H",
        "outputId": "bf1b0405-1b8d-4bf6-fd6a-84f9e5d8fd9c"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the diabetes dataset\n",
        "iris_X, iris_y = datasets.load_iris(return_X_y=True)\n",
        "\n",
        "# Split train:test = 8:2\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris_X,\n",
        "                                                    iris_y,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=42)\n",
        "\n",
        "# Scale the features using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Build KNN Classifier\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predict and Evaluate test set\n",
        "y_pred = knn_classifier.predict (X_test)\n",
        "accuracy_score(y_test, y_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "Jj6Ksqng5ro7",
        "outputId": "d9984136-95ad-46f4-900d-8cfbc2032c70"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "\n",
        "# Paragraph A:\n",
        "# Load the diabetes dataset\n",
        "diabetes_X, diabetes_y = datasets.load_diabetes(return_X_y=True)\n",
        "\n",
        "# Paragraph D:\n",
        "# Split train:test = 8:2\n",
        "X_train, X_test, y_train, y_test = train_test_split(diabetes_X,\n",
        "                                                    diabetes_y,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=42)\n",
        "\n",
        "# Paragraph B:\n",
        "# Scale the features using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Paragraph C:\n",
        "# Build KNN model\n",
        "knn_regressor = KNeighborsRegressor (n_neighbors=5)\n",
        "knn_regressor.fit(X_train, y_train)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0Qbd8j36SJ5",
        "outputId": "43b2a117-b7f0-42f9-c133-4c5d88c6b0c7"
      },
      "outputs": [],
      "source": [
        "!pip install -q datasets\n",
        "!pip install pyarrow==15.0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rs-a8nGa6Oc2",
        "outputId": "892b20e2-768c-45d9-de88-46f08a2b338d"
      },
      "outputs": [],
      "source": [
        "# Import library\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# Load IMDB dataset\n",
        "imdb = load_dataset(\"imdb\")\n",
        "imdb_train, imdb_test = imdb['train'], imdb['test']\n",
        "# Convert text to vector using BoW\n",
        "vectorizer = CountVectorizer (max_features=1000)\n",
        "X_train = vectorizer.fit_transform(imdb_train['text']).toarray()\n",
        "X_test = vectorizer.transform(imdb_test['text']).toarray()\n",
        "\n",
        "y_train = np.array(imdb_train['label'])\n",
        "y_test = np.array(imdb_test['label'])\n",
        "\n",
        "# Scale the features using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Build KNN Classifier\n",
        "knn_classifier = KNeighborsClassifier (n_neighbors=1, algorithm='ball_tree')\n",
        "knn_classifier.fit(X_train, y_train)\n",
        "\n",
        "# predict test set and evaluate\n",
        "y_pred = knn_classifier.predict(X_test)\n",
        "accuracy_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. K-Means"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wgn_u_fRysR4"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "W-ruXqcmyuTU",
        "outputId": "f176ca3f-2abb-49d8-974a-7ccf363900b5"
      },
      "outputs": [],
      "source": [
        "iris_dataset = load_iris()\n",
        "data = iris_dataset.data\n",
        "data = iris_dataset.data[:, :2]\n",
        "\n",
        "# Plot data\n",
        "plt.scatter(data[:, 0], data[:, 1], c='gray')\n",
        "plt.title(\"Initial Dataset\")\n",
        "plt.xlabel('Sepal length')\n",
        "plt.ylabel('Sepal width')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64xC6x4ey6KF"
      },
      "outputs": [],
      "source": [
        "class KMeans:\n",
        "    def __init__(self, k=3, max_iters=20):\n",
        "        self.k = k                   \n",
        "        self.max_iters = max_iters   \n",
        "        self.centroids = None        \n",
        "        self.clusters = None         \n",
        "\n",
        "    def initialize_centroids(self, data):\n",
        "\n",
        "        np.random.seed(42)\n",
        "        self.centroids = data[np.random.choice(data.shape[0], self.k, replace=False)]\n",
        "\n",
        "    def euclidean_distance(self, x1, x2):\n",
        "        return np.sqrt(np.sum(np.power(x1 - x2, 2)))\n",
        "\n",
        "    def assign_clusters(self, data):\n",
        "        distances = np.array([[self.euclidean_distance(x, centroid) for centroid in self.centroids] for x in data])\n",
        "\n",
        "        return np.argmin(distances, axis=1)\n",
        "\n",
        "    def update_centroids(self, data):\n",
        "        return np.array([data[self.clusters == i].mean(axis=0) for i in range(self.k)])\n",
        "\n",
        "    def fit(self, data):\n",
        "        self.initialize_centroids(data)\n",
        "\n",
        "        for i in range(self.max_iters):\n",
        "            self.clusters = self.assign_clusters(data)\n",
        "\n",
        "            self.plot_clusters(data, i)\n",
        "\n",
        "            new_centroids = self.update_centroids(data)\n",
        "\n",
        "            if np.all(self.centroids == new_centroids):\n",
        "                break\n",
        "\n",
        "            self.centroids = new_centroids\n",
        "\n",
        "        self.plot_final_clusters(data)\n",
        "\n",
        "\n",
        "    def plot_clusters(self, data, iteration):\n",
        "        \"\"\"\n",
        "        Vẽ các cụm và tâm cụm tại mỗi iteration\n",
        "        Parameters:\n",
        "            data (numpy.ndarray): dữ liệu đầu vào cần phân cụm\n",
        "            iteration (int): iteration hiện tại\n",
        "        Return:\n",
        "            None\n",
        "        \"\"\"\n",
        "        plt.scatter(data[:, 0], data[:, 1], c=self.clusters, cmap='viridis', marker='o', alpha=0.6)\n",
        "        plt.scatter(self.centroids[:, 0], self.centroids[:, 1], s=300, c='red', marker='x')\n",
        "        plt.title(f\"Iteration {iteration + 1}\")\n",
        "        plt.xlabel('Sepal length')\n",
        "        plt.ylabel('Sepal width')\n",
        "        plt.show()\n",
        "\n",
        "    def plot_final_clusters(self, data):\n",
        "        \"\"\"\n",
        "        Vẽ các cụm và tâm cụm cuối cùng\n",
        "        Parameters:\n",
        "            data (numpy.ndarray): dữ liệu đầu vào cần phân cụm\n",
        "        Return:\n",
        "            None\n",
        "        \"\"\"\n",
        "        plt.scatter(data[:, 0], data[:, 1], c=self.clusters, cmap='viridis', marker='o', alpha=0.6)\n",
        "        plt.scatter(self.centroids[:, 0], self.centroids[:, 1], s=300, c='red', marker='x')\n",
        "        plt.title(\"Final Clusters and Centroids\")\n",
        "        plt.xlabel('Sepal length')\n",
        "        plt.ylabel('Sepal width')\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "HTlQxttE0CcI",
        "outputId": "e88da778-9472-4850-f40e-99624dba403d"
      },
      "outputs": [],
      "source": [
        "kmeans = KMeans(k=2)\n",
        "kmeans.fit(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cPyvymxf0c8z",
        "outputId": "488c9c3f-25b4-4653-9cae-526a29e12ae3"
      },
      "outputs": [],
      "source": [
        "kmeans = KMeans(k=3)\n",
        "kmeans.fit(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "euZ64TMzz7BQ",
        "outputId": "18ee3de1-de31-4b68-d52f-7ea979c5b2a0"
      },
      "outputs": [],
      "source": [
        "kmeans = KMeans(k=4)\n",
        "kmeans.fit(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "px7pwxKd3b9E",
        "outputId": "456034e8-c687-4122-a712-d5f5a6510500"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "\n",
        "num_tuples = 10\n",
        "num_dimensions = 4\n",
        "\n",
        "newdata = [\n",
        "    tuple(random.uniform(1.0, 10.0) for _ in range(num_dimensions))\n",
        "    for _ in range(num_tuples)\n",
        "]\n",
        "\n",
        "\n",
        "newdata = np.array(newdata)\n",
        "kmeans = KMeans(k=3)\n",
        "kmeans.fit(newdata)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
